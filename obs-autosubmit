#!/usr/bin/env python
# vim: set ts=4 sw=4 et: coding=UTF-8

#
# Copyright (c) 2011-2012, SUSE
# All rights reserved.
#
# Redistribution and use in source and binary forms, with or without
# modification, are permitted provided that the following conditions are met:
#
#  * Redistributions of source code must retain the above copyright notice,
#    this list of conditions and the following disclaimer.
#  * Redistributions in binary form must reproduce the above copyright notice,
#    this list of conditions and the following disclaimer in the documentation
#    and/or other materials provided with the distribution.
#  * Neither the name of the <ORGANIZATION> nor the names of its contributors
#    may be used to endorse or promote products derived from this software
#    without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.
#
#
# (Licensed under the BSD 3-Clause license)
#
# Authors: Vincent Untz <vuntz@opensuse.org>
#

import os
import sys

import errno

import datetime
import optparse
import re
import sqlite3
import time
import traceback
import urllib
import urllib2
import urlparse

try:
    from lxml import etree as ET
except ImportError:
    try:
        from xml.etree import cElementTree as ET
    except ImportError:
        import cElementTree as ET


from osc import conf as oscconf
from osc import core


MIN_AGE_DAYS = 7

NO_DEVEL_PACKAGE_SAFE = [ '^_product.*' ]

# Not sure why, but it seems there's some black magic for this specific
# package: it's a link to openSUSE:Factory/glibc, but it's different
INTERNAL_LINK_DIFFERENT_HASH_SAFE = [ 'openSUSE:Factory/glibc.i686' ]


#######################################################################


FILTER_REASON_AUTOSUBMITTED = 'autosubmitted'
FILTER_REASON_ALREADY_AUTOSUBMITTED = 'already-autosubmitted'
FILTER_REASON_SAME_CHANGES_FILE = 'same-changes-file'
FILTER_REASON_DELETE_REQUESTED = 'delete-requested'
FILTER_REASON_AUTOSUBMIT_DISABLED = 'autosubmit-disabled'
FILTER_REASON_ALREADY_SUBMITTED = 'already-submitted'
FILTER_REASON_TOO_RECENT = 'too-recent'
FILTER_REASON_ALREADY_SUBMITTED_PAST = 'already-submitted-past'
FILTER_REASON_OUT_OF_DATE_STATUS = 'out-of-date-status'

FILTER_REASONS_TO_TEXT = {
    FILTER_REASON_AUTOSUBMITTED: 'auto-submitted (%s)',
    FILTER_REASON_ALREADY_AUTOSUBMITTED: 'already auto-submitted (%s)',
    FILTER_REASON_SAME_CHANGES_FILE: '.changes files are the same',
    FILTER_REASON_DELETE_REQUESTED: 'delete request for %s filed',
    FILTER_REASON_AUTOSUBMIT_DISABLED: 'auto-submit disabled',
    FILTER_REASON_TOO_RECENT: 'last changes is too recent (~%s days old)',
    FILTER_REASON_ALREADY_SUBMITTED: 'already submitted (%s)',
    FILTER_REASON_ALREADY_SUBMITTED_PAST: 'already submitted in the past (%s)',
    FILTER_REASON_OUT_OF_DATE_STATUS: 'status info out-of-date (parent package already the same)'
}

# Order in this dict will impact order in output of --stats
FILTER_REASONS_TO_TEXT_STATS = {
    FILTER_REASON_AUTOSUBMITTED: 'Packages automatically submitted',
    FILTER_REASON_ALREADY_AUTOSUBMITTED: 'Packages previously automatically submitted',
    FILTER_REASON_SAME_CHANGES_FILE: 'Packages with no difference in .changes',
    FILTER_REASON_DELETE_REQUESTED: 'Packages with a delete request',
    FILTER_REASON_AUTOSUBMIT_DISABLED: 'Packages with autosubmit disabled',
    FILTER_REASON_TOO_RECENT: 'Packages too recent to be automatically submitted',
    FILTER_REASON_ALREADY_SUBMITTED: 'Packages already submitted',
    FILTER_REASON_ALREADY_SUBMITTED_PAST: 'Packages already submitted in the past but declined/superseded/etc.',
    FILTER_REASON_OUT_OF_DATE_STATUS: 'Packages with no changes (out-of-date status)'
}

STATS_ORDER = [
    FILTER_REASON_AUTOSUBMITTED,
    FILTER_REASON_ALREADY_AUTOSUBMITTED,
    FILTER_REASON_TOO_RECENT,
    FILTER_REASON_SAME_CHANGES_FILE,
    FILTER_REASON_ALREADY_SUBMITTED,
    FILTER_REASON_ALREADY_SUBMITTED_PAST,
    FILTER_REASON_DELETE_REQUESTED,
    FILTER_REASON_AUTOSUBMIT_DISABLED,
    FILTER_REASON_OUT_OF_DATE_STATUS
]

if len(FILTER_REASONS_TO_TEXT) != len(FILTER_REASONS_TO_TEXT_STATS) or len(FILTER_REASONS_TO_TEXT_STATS) != len(STATS_ORDER):
    print >>sys.stderr, 'Internal error: some filter is missing in some places.'
    sys.exit(1)


#######################################################################


NO_DEVEL_PACKAGE_SAFE_REGEXP = [ re.compile(x) for x in NO_DEVEL_PACKAGE_SAFE ]


#######################################################################


def safe_mkdir_p(dir):
    if not dir:
        return

    try:
        os.makedirs(dir)
    except OSError, e:
        if e.errno != errno.EEXIST:
            raise e


#######################################################################


class AutoSubmitException(Exception):
    pass

class AutoSubmitUnlikelyException(AutoSubmitException):
    pass


#######################################################################


class AutoSubmitConfig:

    def __init__(self, options):
        self.cache_dir = options.cache_dir or os.getcwd()
        self.apiurl = options.apiurl or 'https://api.opensuse.org/'
        self.project = options.project or 'openSUSE:Factory'
        self.verbose = options.verbose
        self.debug = options.debug


#######################################################################


def fetch_status_for_project(apiurl, project):
    url = core.makeurl(apiurl, ['status', 'project', project])

    try:
        fin = core.http_GET(url)
    except urllib2.HTTPError, e:
        raise AutoSubmitException('Cannot get status of %s: %s' % (project, e))

    try:
        node = ET.parse(fin).getroot()
    except SyntaxError, e:
        fin.close()
        raise AutoSubmitException('Cannot parse status of %s: %s' % (project, e))

    fin.close()

    return node


#######################################################################


def fetch_requests(apiurl, xpath):
    url = core.makeurl(apiurl, ['search', 'request'], ['match=%s' % urllib.quote_plus(xpath)])

    try:
        fin = core.http_GET(url)
    except urllib2.HTTPError, e:
        raise AutoSubmitException('Cannot get requests submitted to %s: %s' % (project, e))

    try:
        node = ET.parse(fin).getroot()
    except SyntaxError, e:
        fin.close()
        raise AutoSubmitException('Cannot parse requests submitted to %s: %s' % (project, e))

    fin.close()

    return node


def fetch_requests_for_project(apiurl, project, package = None):
    xpath = '(action/@type=\'submit\' or action/@type=\'delete\') and (state/@name=\'new\' or state/@name=\'review\') and (action/target/@project=\'%(project)s\' or submit/target/@project=\'%(project)s\')' % { 'project': project }

    return fetch_requests(apiurl, xpath)


def fetch_all_requests_for_package(apiurl, project, package):
    xpath = 'action/@type=\'submit\' and (action/target/@project=\'%(project)s\' or submit/target/@project=\'%(project)s\') and (action/target/@package=\'%(package)s\' or submit/target/@package=\'%(package)s\')' % { 'project': project, 'package': package }

    return fetch_requests(apiurl, xpath)


#######################################################################


def fetch_package_files_metadata(apiurl, project, package, revision = None, expand = False):
    query = {}
    if revision:
        query['rev'] = revision
    if expand:
        query['expand'] = '1'

    url = core.makeurl(apiurl, ['public', 'source', project, package], query=query)

    try:
        fin = core.http_GET(url)
    except urllib2.HTTPError, e:
        raise AutoSubmitException('Cannot get files metadata of %s/%s: %s' % (project, package, e))

    try:
        node = ET.parse(fin).getroot()
    except SyntaxError, e:
        fin.close()
        raise AutoSubmitException('Cannot parse files metadata of %s/%s: %s' % (project, package, e))

    fin.close()

    return node


#######################################################################


def fetch_package_info(apiurl, project, package, revision = None):
    query = {'view': 'info'}
    if revision:
        query['rev'] = revision

    url = core.makeurl(apiurl, ['public', 'source', project, package], query=query)

    try:
        fin = core.http_GET(url)
    except urllib2.HTTPError, e:
        raise AutoSubmitException('Cannot get info of %s/%s: %s' % (project, package, e))

    try:
        node = ET.parse(fin).getroot()
    except SyntaxError, e:
        fin.close()
        raise AutoSubmitException('Cannot parse info of %s/%s: %s' % (project, package, e))

    fin.close()

    return node


#######################################################################


def fetch_attributes(apiurl, project, package = None):
    if package:
        url = core.makeurl(apiurl, ['source', project, package, '_attribute'])
        err_str = '%s/%s' % (package, project)
    else:
        url = core.makeurl(apiurl, ['source', project, '_attribute'])
        err_str = project

    try:
        fin = core.http_GET(url)
    except urllib2.HTTPError, e:
        raise AutoSubmitException('Cannot get attributes of %s: %s' % (err_str, e))

    try:
        attributes_node = ET.parse(fin).getroot()
    except SyntaxError, e:
        fin.close()
        raise AutoSubmitException('Cannot parse attributes of %s: %s' % (err_str, e))

    fin.close()

    attributes = {}

    for attribute_node in attributes_node.findall('attribute'):
        namespace = attribute_node.get('namespace')
        name = attribute_node.get('name')

        if not namespace or not name:
            print >>sys.stderr, 'Ignoring an attribute of %s with missing namespace or name.' % err_str
            continue

        value = []
        for value_node in attribute_node.findall('value'):
            value.append(value_node.text)
        if not value:
            value = ''
        elif len(value) == 1:
            value = value[0]

        attributes['%s:%s' % (namespace, name)] = value

    return attributes


#######################################################################


def create_submit_request(apiurl, source_project, source_package, rev, target_project, target_package):
    request = ET.Element('request')
    request.set('type', 'submit')

    submit = ET.SubElement(request, 'submit')

    source = ET.SubElement(submit, 'source')
    source.set('project', source_project)
    source.set('package', source_package)
    source.set('rev', rev)

    target = ET.SubElement(submit, 'target')
    target.set('project', target_project)
    target.set('package', target_package)

    state = ET.SubElement(request, 'state')
    state.set('name', 'new')

    description = ET.SubElement(request, 'description')
    description.text = 'Automatic submission by obs-autosubmit'

    tree = ET.ElementTree(request)
    xml = ET.tostring(tree)

    url = core.makeurl(apiurl, ['request'], query='cmd=create')

    try:
        fin = core.http_POST(url, data=xml)
    except urllib2.HTTPError, e:
        raise AutoSubmitException('Cannot submit %s to %s: %s' % (source_project, source_package, target_project, target_package, e))

    try:
        node = ET.parse(fin).getroot()
    except SyntaxError, e:
        fin.close()
        raise AutoSubmitException('Cannot parse result of submission of %s to %s: %s' % (source_project, source_package, target_project, target_package, e))

    fin.close()

    return node.get('id')


#######################################################################


class AutoSubmitPackage:
    '''
        Small note about the hashes:

         - unexpanded_hash: hash of the unexpanded sources
         - hash: this is, more or less, the hash of the expanded sources.
           ("more or less" because this is verifymd5, which is apparently used
           internally in OBS by the scheduler; it's not the hash we get by
           default)

        For all that matters, we're really interested in hash when comparing
        packages to see if there's a diff, not unexpanded_hash.
    '''

    def __init__(self, project, package, state_hash = '', unexpanded_state_hash = '', rev = '', changes_hash = '', max_mtime = 0):
        self.project = project
        self.package = package
        self.state_hash = state_hash
        self.unexpanded_state_hash = unexpanded_state_hash
        self.rev = rev
        self.changes_hash = changes_hash
        self.max_mtime = max_mtime
        self.attributes = None


    def fetch_latest_package_state(self, apiurl, nodetails = False):
        sourceinfo_node = fetch_package_info(apiurl, self.project, self.package)

        rev = sourceinfo_node.get('rev')
        unexpanded_state_hash = sourceinfo_node.get('srcmd5')
        state_hash = sourceinfo_node.get('verifymd5') or unexpanded_state_hash

        if not rev or not unexpanded_state_hash:
            raise AutoSubmitException('Cannot fetch current state of %s' % (self,))

        self.rev = rev
        self.unexpanded_state_hash = unexpanded_state_hash

        # State hash might be the same -- for instance, after "baserev update by copy to link target" commits from buildservice-autocommit
        # In that case, we don't need to fetch the other details (unless we don't have max_mtime yet)
        if state_hash == self.state_hash and self.max_mtime != 0:
            # We were up-to-date, that's cool
            return

        self.state_hash = state_hash

        if nodetails:
            return

        # Update changes_hash
        directory_node = fetch_package_files_metadata(apiurl, self.project, self.package, expand = True)

        self.changes_md5 = None

        for entry_node in directory_node.findall('entry'):
            name = entry_node.get('name') or ''
            md5 = entry_node.get('md5')
            try:
                mtime = int(entry_node.get('mtime') or '')
            except ValueError:
                # we don't raise an AutoSubmitException since it's not critical
                mtime = 0

            self.max_mtime = max(mtime, self.max_mtime)

            if name.endswith('.changes') and not md5:
                raise AutoSubmitException('Cannot fetch hash of changes file for %s' % (self,))

            if name == '%s.changes' % self.package:
                self.changes_md5 = md5


    def fetch_attributes(self, apiurl):
        if self.attributes is not None:
            # already fetched
            return

        self.attributes = fetch_attributes(apiurl, self.project, self.package)


    @classmethod
    def from_status_node(cls, node):
        project = node.get('project')
        package = node.get('name')
        unexpanded_md5 = node.get('srcmd5')
        expanded_md5 = node.get('verifymd5') or unexpanded_md5
        changes_md5 = node.get('changesmd5')
        try:
            max_mtime = int(node.get('maxmtime') or '')
        except ValueError:
            # we don't raise an AutoSubmitException since it's not critical
            max_mtime = 0

        if not expanded_md5:
            raise AutoSubmitUnlikelyException('no state hash for %s/%s (?)' % (project, package))

        return AutoSubmitPackage(project, package, state_hash = expanded_md5, unexpanded_state_hash = unexpanded_md5, changes_hash = changes_md5, max_mtime = max_mtime)


    @classmethod
    def from_status_develpack_node(cls, develpack_node):
        project = develpack_node.get('proj')
        package = develpack_node.get('pack')

        package_node = develpack_node.find('package')
        if package_node is not None:
            ret = AutoSubmitPackage.from_status_node(package_node)
            if ret.project == project and ret.package == package:
                return ret
            else:
                raise AutoSubmitUnlikelyException('inconsistent develpack and package nodes')
        else:
            raise AutoSubmitUnlikelyException('no package node in develpack node')


    @classmethod
    def from_request_node(cls, node):
        project = node.get('project')
        package = node.get('package')
        rev = node.get('rev')

        return AutoSubmitPackage(project, package, rev = rev)


    # Note: we do not use the state hash below; this makes it easy to know
    # if we're looking at the same package even if its content is different

    def __eq__(self, other):
        return self.project == other.project and self.package == other.package

    def __ne__(self, other):
        return not self.__eq__(other)

    def __lt__(self, other):
        return str(self) < str(other)

    def __le__(self, other):
        return self.__eq__(other) or self.__lt__(other)

    def __gt__(self, other):
        return other.__lt__(self)

    def __ge__(self, other):
        return other.__eq__(self) or other.__lt__(self)

    def __str__(self):
        return '%s/%s' % (self.project, self.package)


#######################################################################


class AutoSubmitCache:
    ''' The cache only contains packages with a difference as of now, with
        each of them belonging to one category:
          - the list of packages that we filtered (since they should stay
            ignored).
          - the list of packages that we successfully submitted (since they
            should be ignored now).
        We need to put the second category in there, else we'll rely on the
        "look at new submit requests" filter, which requires some traffic.

        See hash documentation in AutoSubmitPackage for why we use state_hash
        and not unexpanded_state_hash
    '''

    def __init__(self, conf):
        self.conf = conf
        self._dbfile = os.path.join(self.conf.cache_dir, 'cache.db')

        self.dbmeta = None
        self.cursor = None
        self.run_id = None

        self._init_db()


    def _init_db(self):
        create = True
        if os.path.exists(self._dbfile):
            create = False
            if not os.access(self._dbfile, os.W_OK):
                raise AutoSubmitUnlikelyException('\'%s\' is read-only. Cache database must be writable.' % self._dbfile)
        else:
            dirname = os.path.dirname(self._dbfile)
            if not os.path.exists(dirname):
                os.makedirs(dirname)

        self.dbmeta = sqlite3.connect(self._dbfile)
        if not self.dbmeta:
            raise AutoSubmitUnlikelyException('No access to cache database.' % self._dbfile)

        self.dbmeta.row_factory = sqlite3.Row
        self.cursor = self.dbmeta.cursor()

        if create:
            self.cursor.execute('''CREATE TABLE run (id INTEGER PRIMARY KEY ASC, apiurl TEXT, project TEXT, date_start TEXT, date_end TEXT);''')
            self.cursor.execute('''CREATE TABLE filtered (run_id INTEGER, parent_project TEXT, parent_package TEXT, devel_project TEXT, devel_package TEXT, devel_state_hash TEXT, filter_reason TEXT, filter_reason_data TEXT);''')
            self.cursor.execute('''CREATE TABLE failed (run_id INTEGER, parent_project TEXT, parent_package TEXT, devel_project TEXT, devel_package TEXT, devel_state_hash TEXT);''')


    def start_run(self):
        if self.run_id != None:
            raise AutoSubmitUnlikelyException('Cannot add a new run to cache database: already running!')

        self.cursor.execute('''INSERT INTO run VALUES (NULL, ?, ?, datetime('now'), 0);''', (self.conf.apiurl, self.conf.project))
        self.cursor.execute('''SELECT MAX(id) FROM run;''')
        row = self.cursor.fetchone()
        if not row:
            raise AutoSubmitUnlikelyException('Cannot fetch id of new run in cache database.')

        self.run_id = row[0]


    def end_run(self):
        if self.run_id is None:
            raise AutoSubmitUnlikelyException('Cannot end run in cache database: not running!')

        self.cursor.execute('''UPDATE run SET date_end = datetime('now') WHERE id = ?;''', (self.run_id,))
        self.run_id = None


    def get_from_cache(self, parent_project, parent_package):
        # We return the latest cache entry for this parent package; we don't care about older entries
        self.cursor.execute('''SELECT * FROM filtered WHERE parent_project = ? AND parent_package = ? ORDER BY run_id DESC LIMIT 1;''', (parent_project, parent_package))
        row = self.cursor.fetchone()
        if row:
            return (row['devel_project'], row['devel_package'], row['devel_state_hash'], row['filter_reason'], row['filter_reason_data'])
        else:
            return (None, None, None, None, None)


    def add_to_cache(self, parent_project, parent_package, devel_project, devel_package, devel_state_hash, filter_reason, filter_reason_data):
        if self.run_id is None:
            raise AutoSubmitUnlikelyException('Cannot add entry to cache database: not running!')

        self.cursor.execute('''INSERT INTO filtered VALUES (?, ?, ?, ?, ?, ?, ?, ?);''', (self.run_id, parent_project, parent_package, devel_project, devel_package, devel_state_hash, filter_reason, filter_reason_data or ''))


    def add_to_cache_failed(self, parent_project, parent_package, devel_project, devel_package, devel_state_hash):
        if self.run_id is None:
            raise AutoSubmitUnlikelyException('Cannot add entry to cache database: not running!')

        self.cursor.execute('''INSERT INTO failed VALUES (?, ?, ?, ?, ?, ?);''', (self.run_id, parent_project, parent_package, devel_project, devel_package, devel_state_hash))


    def prune_old_entries(self):
        self.cursor.execute('''SELECT id FROM run WHERE datetime(date_end, '+7 days') < datetime('now');''')
        delete_ids = [ row['id'] for row in self.cursor.fetchall() ]
        for delete_id in delete_ids:
            self.cursor.execute('''DELETE FROM filtered WHERE run_id = ?;''', delete_id)
            self.cursor.execute('''DELETE FROM failed WHERE run_id = ?;''', delete_id)
            self.cursor.execute('''DELETE FROM run WHERE id = ?;''', delete_id)


    def commit(self):
        if self.dbmeta:
            self.dbmeta.commit()


    def get_run(self, nth_run_from_last = 0):
        self.cursor.execute('''SELECT * FROM run WHERE apiurl = ? AND project = ? ORDER BY id DESC LIMIT 1 OFFSET ?;''', (self.conf.apiurl, self.conf.project, nth_run_from_last,))
        row = self.cursor.fetchone()
        if row:
            return (row['id'], row['date_start'], row['date_end'])
        else:
            return (None, None, None)


    def count(self, run_id):
        self.cursor.execute('''SELECT COUNT(*) FROM filtered WHERE run_id = ?;''', (run_id,))
        row = self.cursor.fetchone()
        return int(row[0])


    def count_failed(self, run_id):
        self.cursor.execute('''SELECT COUNT(*) FROM failed WHERE run_id = ?;''', (run_id,))
        row = self.cursor.fetchone()
        return int(row[0])


    def count_by_reason(self, run_id):
        self.cursor.execute('''SELECT filter_reason, COUNT(*) FROM filtered WHERE run_id = ? GROUP BY filter_reason;''', (run_id,))
        counts = {}
        for row in self.cursor.fetchall():
            counts[row[0]] = row[1]
        return counts


    def __del__(self):
        if self.cursor:
            self.cursor.close()
        if self.dbmeta:
            self.dbmeta.commit()
            self.dbmeta.close()


#######################################################################


class AutoSubmitWorker:

    def __init__(self, conf):
        self.conf = conf
        self._blacklisted_projects = []
        self._blacklisted_packages = []
        self._projects_attributes = {}


    def _verbose_print(self, s, level = 1):
        if self.conf.verbose >= level:
            print s


    def _read_blacklist(self):
        # reinit blacklist
        self._blacklisted_projects = []
        self._blacklisted_packages = []

        blacklist_file = os.path.join(os.path.dirname(__file__), 'blacklist')
        if not os.path.exists(blacklist_file):
            return

        fd = open(blacklist_file, 'r')
        lines = fd.readlines()
        fd.close()

        for line in lines:
            line = line.strip()
            if not line or line.startswith('#'):
                continue

            items = line.split('/')

            if len(items) > 2:
                print >>sys.stderr, 'Ignoring weird blacklist line: %s' % line
                continue

            if len(items) == 1 or not items[1]:
                self._blacklisted_projects.append(items[0])
            else:
                self._blacklisted_packages.append('%s/%s' % (items[0], items[1]))


    def _fetch_packages_with_diff(self):
        xml_root = fetch_status_for_project(self.conf.apiurl, self.conf.project)

        with_diff_hash = {}
        self._packages_with_diff = []

        for package_node in xml_root.findall('package'):
            try:
                parent_package = AutoSubmitPackage.from_status_node(package_node)
            except AutoSubmitUnlikelyException, e: 
                print >>sys.stderr, 'Cannot get package: %s' % e
                continue

            if parent_package.project != self.conf.project:
                print >>sys.stderr, '%s found as parent package while auto-submitting to %s.' % (parent_package, self.conf.project)
                continue

            develpack_node = package_node.find('develpack')
            if develpack_node is None:
                safe = False
                for regexp in NO_DEVEL_PACKAGE_SAFE_REGEXP:
                    match = regexp.match(parent_package.package)
                    if match:
                        safe = True
                        break

                if not safe:
                    print >>sys.stderr, 'No devel package for %s.' % parent_package
                continue

            try:
                devel_package = AutoSubmitPackage.from_status_develpack_node(develpack_node)
            except AutoSubmitUnlikelyException, e: 
                print >>sys.stderr, 'Cannot get devel package for %s: %s' % (parent_package, e)
                continue

            # See hash documentation in AutoSubmitPackage for why we use
            # state_hash and not unexpanded_state_hash
            if parent_package.state_hash == devel_package.state_hash:
                continue

            if devel_package.project == self.conf.project:
                if str(parent_package) not in INTERNAL_LINK_DIFFERENT_HASH_SAFE:
                    print >>sys.stderr, 'Devel package %s (for %s) belongs to target project %s but state hash is different: this should never happen.' % (devel_package, parent_package, self.conf.project)
                continue

            hash_key = str(parent_package)
            if with_diff_hash.has_key(hash_key):
                print >>sys.stderr, '%s appearing twice as parent package.' % parent_package
                continue

            with_diff_hash[hash_key] = True

            self._packages_with_diff.append((devel_package, parent_package))

        self._packages_with_diff.sort()


    def _fetch_existing_requests(self):
        xml_root = fetch_requests_for_project(self.conf.apiurl, self.conf.project)

        self._submit_requests = {}
        self._delete_requests = {}

        for request_node in xml_root.findall('request'):
            request_id = request_node.get('id')
            if not request_id:
                print >>sys.stderr, 'Ignoring request with no request id.'
                continue

            for action_node in request_node.findall('action'):
                action_type = action_node.get('type')
                if not action_type:
                    print >>sys.stderr, 'Ignoring request %s: no action type.' % request_id
                    continue

                if action_type not in ('submit', 'delete'):
                    print >>sys.stderr, 'Ignoring request %s: action type \'%s\' not expected.' % (request_id, action_type)
                    continue

                source = None
                target = None

                source_node = action_node.find('source')
                if source_node is not None:
                    source = AutoSubmitPackage.from_request_node(source_node)
                target_node = action_node.find('target')
                if target_node is not None:
                    target = AutoSubmitPackage.from_request_node(target_node)

                if not target:
                    print >>sys.stderr, 'Ignoring request %s: target mis-defined.' % request_id
                    continue

                key = str(target)

                if action_type == 'submit':
                    if not source:
                        print >>sys.stderr, 'Ignoring submit request %s: source mis-defined.' % request_id
                        continue

                    new = (request_id, source)
                    if not self._submit_requests.has_key(key):
                        requests = [ new ]
                    else:
                        requests = self._submit_requests[key].append(new)
                    self._submit_requests[key] = requests
                elif action_type == 'delete':
                    if not self._delete_requests.has_key(key):
                        requests = [ request_id ]
                    else:
                        requests = self._delete_requests[key].append(key)
                    self._delete_requests[key] = requests


    def _devel_package_check_already_submitted(self, devel_package, parent_package):
        xml_root = fetch_all_requests_for_package(self.conf.apiurl, parent_package.project, parent_package.package)

        for request_node in xml_root.findall('request'):
            request_id = request_node.get('id')
            if not request_id:
                print >>sys.stderr, 'Ignoring request with no request id.'
                continue

# FIXME: this is really only a workaround needed because of a test run where autosubmit was not disabled. Can be dropped after the first real run.
            try:
                if int(request_id) in range(102244,102266+1):
                    continue
            except ValueError:
                pass

            for action_node in request_node.findall('action'):
                action_type = action_node.get('type')
                if not action_type:
                    print >>sys.stderr, 'Ignoring request %s: no action type.' % request_id
                    continue

                if action_type not in ('submit',):
                    print >>sys.stderr, 'Ignoring request %s: action type \'%s\' not expected.' % (request_id, action_type)
                    continue

                source = None

                source_node = action_node.find('source')
                if source_node is not None:
                    source = AutoSubmitPackage.from_request_node(source_node)

                if not source:
                    print >>sys.stderr, 'Ignoring request %s: source mis-defined.' % request_id
                    continue

                if devel_package == source and devel_package.rev == source.rev:
                    return request_id

        return None


    def _auto_submit_enabled(self, package):
        ''' Checks if auto-submit is disabled for this package.

            By default, it's all enabled. But there might be some attribute in OBS
            to disable this.

            We first check if it's disabled for the project.
        '''
        def is_disabled_via_attribute(attributes):
            if not attributes.has_key('openSUSE:DisableAutoSubmit'):
                return False
            value = attributes['openSUSE:DisableAutoSubmit']
            if type(value) == list:
                # Can't handle that, really
                return False
            if type(value) != str:
                print >>sys.stderr, 'Unexpected attribute type: %s' (type(value),)
                return False
            return value.lower() in [ 'true', '1' ]

        if package.project in self._blacklisted_projects:
            return False

        if str(package) in self._blacklisted_packages:
            return False

        if not self._projects_attributes.has_key(package.project):
            self._projects_attributes[package.project] = fetch_attributes(self.conf.apiurl, package.project)
        if is_disabled_via_attribute(self._projects_attributes[package.project]):
            self._verbose_print('Auto-submit for %s disabled by project attribute.' % package, level = 2)
            return False

        package.fetch_attributes(self.conf.apiurl)
        if is_disabled_via_attribute(package.attributes):
            self._verbose_print('Auto-submit for %s disabled by package attribute.' % package, level = 2)
            return False

        return True


    def _should_filter_package(self, devel_package, parent_package):
        ''' To know if we need to create a submit request, we check the
            following:
            a) Checks that do not require any network activity
               1) the current state of the devel package is not a state we've
                  already seen
               2) there is a diff in .changes between devel and parent
               3) the parent package has no deleterequest associated to it (we
                  have the list of requests already)
            b) Checks that do require network activity
               1) auto-submit is enabled for the devel package (or for the
                  whole devel project)
               2) state of the devel package we got via the status API is still
                  current; if no, go back to a) with up-to-date state.
                  We also fetch the rev from devel package at this point.
               3) there is an open submit request for this state in the devel
                  package (we have the list of requests already, but we need
                  data fetched in b.2.)
               4) there was a submit request (even if revoked,
                  superseded, etc.) with the same state in the devel package
                  (we need to fetch old submit requests for this package)
               5) the last change in the package (mtime of files) is not too
                  recent (we need data fetched in b.2.)

            Note: we cannot rely on state_hash here. There's no guarantee we'll
            still have a valid expanded hash anymore -- this can happen if we
            re-enter this method after b.2.
        '''
        def _get_reason_text(reason, reason_data):
            text = FILTER_REASONS_TO_TEXT[reason]
            if '%s' in text:
                return text % (reason_data or '',)
            else:
                return text

        def _verbose_print_not_submitting(self, devel_package, parent_package, reason, reason_data):
            reason_text = _get_reason_text(reason, reason_data)
            self._verbose_print('Not submitting %s to %s: %s.' % (devel_package, parent_package, reason_text))

        # a.1. Was already seen/handled in the past; this cache is not completely useless! ;-)
        (cached_devel_project, cached_devel_package, cached_devel_state_hash, cached_reason, cached_reason_data) = self._cache.get_from_cache(parent_package.project, parent_package.package)
        # See hash documentation in AutoSubmitPackage for why we use state_hash
        # and not unexpanded_state_hash
        # We explicitly do not use the cache for the reasons that might not be valid anymore
        if cached_devel_project == devel_package.project and cached_devel_package == devel_package.package and cached_devel_state_hash == devel_package.state_hash and cached_reason not in [FILTER_REASON_DELETE_REQUESTED, FILTER_REASON_AUTOSUBMIT_DISABLED, FILTER_REASON_TOO_RECENT]:
            self._verbose_print('Not submitting %s to %s: changes already seen in the past [%s].' % (devel_package, parent_package, _get_reason_text(cached_reason, cached_reason_data)))
            if cached_reason == FILTER_REASON_AUTOSUBMITTED:
                cached_reason = FILTER_REASON_ALREADY_AUTOSUBMITTED
            return (True, cached_reason, cached_reason_data)

        # a.2. The .changes files are the same, so not worth submitting.
        # (Ignored if the status API doesn't have the attributes for .changes hash)
        if parent_package.changes_hash and parent_package.changes_hash == devel_package.changes_hash:
            _verbose_print_not_submitting(self, devel_package, parent_package, FILTER_REASON_SAME_CHANGES_FILE, None)
            return (True, FILTER_REASON_SAME_CHANGES_FILE, None)

        # a.3. The parent package is, apparently, scheduled to be deleted. If the delete request is rejected, we'll submit on next run anyway.
        if self._delete_requests.has_key(str(parent_package)):
            _verbose_print_not_submitting(self, devel_package, parent_package, FILTER_REASON_DELETE_REQUESTED, str(parent_package))
            return (True, FILTER_REASON_DELETE_REQUESTED, str(parent_package))

        # b.1. Auto-submit is enabled for the devel package (or for the whole devel project)
        if not self._auto_submit_enabled(devel_package):
            _verbose_print_not_submitting(self, devel_package, parent_package, FILTER_REASON_AUTOSUBMIT_DISABLED, None)
            return (True, FILTER_REASON_AUTOSUBMIT_DISABLED, None)

        # b.2. State of the devel package we got via the status API is still current
        # This is also where we fetch rev, needed for the submit request. If we
        # have a rev, that means we've called that already.
        if not devel_package.rev:
            old_hash = devel_package.state_hash
            devel_package.fetch_latest_package_state(self.conf.apiurl)
            # See hash documentation in AutoSubmitPackage for why we use
            # state_hash and not unexpanded_state_hash
            if old_hash != devel_package.state_hash:
                # Devel package is more recent, let's check everything for the most recent version
                return self._should_filter_package(devel_package, parent_package)

        # b.3. There is already an open submit request; we need to see if this is for the current state of the source package.
        if self._submit_requests.has_key(str(parent_package)):
            old_sr = None
            requests = self._submit_requests[str(parent_package)]
            for (request_id, source) in requests:
                if devel_package != source:
                    continue

                if source.rev == devel_package.rev:
                    old_sr = request_id
                    break

            if old_sr is not None:
                _verbose_print_not_submitting(self, devel_package, parent_package, FILTER_REASON_ALREADY_SUBMITTED, old_sr)
                return (True, FILTER_REASON_ALREADY_SUBMITTED, old_sr)
            else:
                self._verbose_print('Should submit %s to %s with newer version.' % (devel_package, parent_package))

        # b.4. There was a submit request (even if revoked, superseded, etc.) with the same state in the devel package
        old_sr = self._devel_package_check_already_submitted(devel_package, parent_package)
        if old_sr is not None:
            _verbose_print_not_submitting(self, devel_package, parent_package, FILTER_REASON_ALREADY_SUBMITTED_PAST, old_sr)
            return (True, FILTER_REASON_ALREADY_SUBMITTED_PAST, old_sr)

        if not parent_package.rev:
            old_hash = parent_package.state_hash
            parent_package.fetch_latest_package_state(self.conf.apiurl, nodetails = True)
            # See hash documentation in AutoSubmitPackage for why we use
            # state_hash and not unexpanded_state_hash
            if parent_package.state_hash ==  devel_package.state_hash:
                _verbose_print_not_submitting(self, devel_package, parent_package, FILTER_REASON_OUT_OF_DATE_STATUS, None)
                return (True, FILTER_REASON_OUT_OF_DATE_STATUS, None)

        # b.5. The last change in the package is not too recent
        timedelta = datetime.timedelta(seconds = int(time.time()) - devel_package.max_mtime)
        if timedelta.days < MIN_AGE_DAYS:
            _verbose_print_not_submitting(self, devel_package, parent_package, FILTER_REASON_TOO_RECENT, str(timedelta.days))
            return (True, FILTER_REASON_TOO_RECENT, str(timedelta.days))

        return (False, None, None)


    def _do_auto_submit(self, devel_package, parent_package):
        if self.conf.debug:
            self._verbose_print('Pretending to submit %s to %s (debug mode)' % (devel_package, parent_package))
            return 0

        self._verbose_print('Submitting %s to %s' % (devel_package, parent_package))
        try:
            id = create_submit_request(self.conf.apiurl, devel_package.project, devel_package.package, devel_package.rev, parent_package.project, parent_package.package)
            self._verbose_print('Submitted %s to %s: %s' % (devel_package, parent_package, id), level = 2)
            return id
        except Exception, e:
            print >>sys.stderr, 'Failed to submit %s to %s: %s' (devel_package, parent_package, e)
        return 0


    def run(self):
        self._cache = AutoSubmitCache(self.conf)

        self._read_blacklist()
        if self.conf.debug:
            print '#####################################################'
            print '%d blacklisted projects' % len(self._blacklisted_projects)
            print '#####################################################'
            for project in self._blacklisted_projects:
                print project
            print ''

            print '#####################################################'
            print '%d blacklisted packages' % len(self._blacklisted_packages)
            print '#####################################################'
            for package in self._blacklisted_packages:
                print package
            print ''

        self._fetch_packages_with_diff()
        if self.conf.debug:
            print '#####################################################'
            print 'Packages with a diff (%d)' % len(self._packages_with_diff)
            print '#####################################################'
            for (devel_package, parent_package) in self._packages_with_diff:
                print '%s -> %s' % (str(devel_package), str(parent_package))
            print ''

        self._fetch_existing_requests()
        if self.conf.debug:
            print '#####################################################'
            print 'Packages already with a submission (%d)' % len(self._submit_requests)
            print '#####################################################'
            for (key, value) in self._submit_requests.items():
                output = [ 'from %s (%s)' % (str(source), request_id) for (request_id, source) in value ]
                print 'Requests to %s: %s' % (key, ','.join(output))
            print ''

            print '#####################################################'
            print 'Packages scheduled for deletion (%d)' % len(self._delete_requests)
            print '#####################################################'
            for (key, value) in self._delete_requests.items():
                print 'Delete requests for %s: %s' % (key, ','.join(value))
            print ''

            print '#####################################################'
            print 'Filtering and submitting'
            print '#####################################################'

        self._cache.start_run()

        try:
            for (devel_package, parent_package) in self._packages_with_diff:
                update_cache = False

                try:
                    (should_filter, filter_reason, filter_reason_data) = self._should_filter_package(devel_package, parent_package)
                    if should_filter:
                        update_cache = True
                        if self.conf.debug:
                            print 'Filtered %s -> %s' % (str(devel_package), str(parent_package))
                    else:
                        if self.conf.debug:
                            print 'Submitting %s -> %s' % (str(devel_package), str(parent_package))
                        sr_id = self._do_auto_submit(devel_package, parent_package)
                        if sr_id > 0:
                            filter_reason = FILTER_REASON_AUTOSUBMITTED
                            filter_reason_data = sr_id
                            update_cache = True
                except Exception, e:
                    print >>sys.stderr, 'Failed to deal with %s to %s: %s' % (devel_package, parent_package, e)

                if update_cache:
                    # See hash documentation in AutoSubmitPackage for why we
                    # use state_hash and not unexpanded_state_hash
                    self._cache.add_to_cache(parent_package.project, parent_package.package, devel_package.project, devel_package.package, devel_package.state_hash, filter_reason, filter_reason_data)
                else:
                    self._cache.add_to_cache_failed(parent_package.project, parent_package.package, devel_package.project, devel_package.package, devel_package.state_hash)

        except Exception, e:
            # We really, really, really want to commit the cache in all cases
            self._cache.commit()
            raise e
        finally:
            self._cache.commit()

        self._cache.end_run()
        self._cache.prune_old_entries()
        self._cache.commit()

        del self._cache
        self._cache = None


    def stats(self, nth_run_from_last):
        self._cache = AutoSubmitCache(self.conf)

        (run_id, date_start, date_end) = self._cache.get_run(nth_run_from_last = nth_run_from_last)
        if run_id is None:
            if nth_run_from_last == 0:
                print >>sys.stderr, 'No run in cache database.'
            else:
                print >>sys.stderr, 'No such run in cache database.'
            return
        incomplete_run = (date_end == '0')

        processed = self._cache.count(run_id)
        failed = self._cache.count_failed(run_id)
        filtered_stats = self._cache.count_by_reason(run_id)

        print 'Successfully processed %s packages with changes in run from %s' % (processed, date_start)
        if failed > 0:
            print 'Failed to process %s packages :/' % failed
        if incomplete_run:
            print 'NOTE: that run was not fully completed.'
        print ''

        for reason in STATS_ORDER:
            if filtered_stats.has_key(reason):
                print '%s: %s' % (FILTER_REASONS_TO_TEXT_STATS[reason], filtered_stats[reason])
            else:
                print '%s: %d' % (FILTER_REASONS_TO_TEXT_STATS[reason], 0)

        del self._cache
        self._cache = None


#######################################################################


def lock_run(conf):
    # FIXME: this is racy, we need a real lock file. Or use an atomic operation
    # like mkdir instead
    running_file = os.path.join(conf.cache_dir, 'running')

    if os.path.exists(running_file):
        return False

    open(running_file, 'w').write('')

    return True


def unlock_run(conf):
    running_file = os.path.join(conf.cache_dir, 'running')

    os.unlink(running_file)


#######################################################################


def main(args):
    parser = optparse.OptionParser()

    parser.add_option('--stats', action='store_true',
                      default=False, dest='stats',
                      help='output statistics about the last run instead and quit')
    parser.add_option('--nth-run', type='int',
                      default=0, dest='nth_run',
                      help='compute statistics for run NTH_RUN (counting from last) instead of last run')
    parser.add_option('--cache-dir', dest='cache_dir',
                      help='cache directory (default: current directory)')
    parser.add_option('--apiurl', '-A', dest='apiurl', default='https://api.opensuse.org/',
                      help='build service API server (default: https://api.opensuse.org/)')
    parser.add_option('--project', '-p', dest='project', default='openSUSE:Factory',
                      help='target project to auto-submit to (default: openSUSE:Factory)')
    parser.add_option('--log', dest='log',
                      help='log file to use (default: stderr)')
    parser.add_option('--verbose', '-v', action='count',
                      default=0, dest='verbose',
                      help='be verbose; use multiple times to add more verbosity (default: false)')
    parser.add_option('--debug', action='store_true',
                      default=False, dest='debug',
                      help='add debug output and do not create real submit requests (default: false)')

    (options, args) = parser.parse_args()

    if options.nth_run != 0 and not options.stats:
        print >>sys.stderr, '--nth-run can only be used with --stats.'
        return 1

    if options.nth_run < 0:
        print >>sys.stderr, 'Value passed to --nth-run must be a positive integer.'
        return 1

    conf = AutoSubmitConfig(options)

    if options.log:
        path = os.path.realpath(options.log)
        safe_mkdir_p(os.path.dirname(path))
        sys.stderr = open(options.log, 'a')

    oscconf.get_config(override_apiurl = conf.apiurl)

    try:
        os.makedirs(conf.cache_dir)
    except OSError, e:
        if e.errno != errno.EEXIST:
            print >>sys.stderr, 'Cannot create cache directory: %s' % e
            return 1

    try:
        if not lock_run(conf):
            print >>sys.stderr, 'Another instance of the script is running.'
            return 1

        worker = AutoSubmitWorker(conf)

        retval = 1

        try:
            if options.stats:
                worker.stats(options.nth_run)
            else:
                worker.run()
            retval = 0
        except Exception, e:
            if isinstance(e, (AutoSubmitException,)):
                print >>sys.stderr, e
            else:
                traceback.print_exc()

    except KeyboardInterrupt:
        # Handle this nicely as we want to remove the lock
        print 'Interrupted...'
        retval = 0

    unlock_run(conf)

    return retval


if __name__ == '__main__':
    try:
        ret = main(sys.argv)
        sys.exit(ret)
    except KeyboardInterrupt:
        pass
